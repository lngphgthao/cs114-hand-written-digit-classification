{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12249632,"sourceType":"datasetVersion","datasetId":7718393},{"sourceId":12249902,"sourceType":"datasetVersion","datasetId":7718548}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2025-06-27T14:48:45.594502Z","iopub.execute_input":"2025-06-27T14:48:45.595146Z","iopub.status.idle":"2025-06-27T14:48:45.853864Z","shell.execute_reply.started":"2025-06-27T14:48:45.595123Z","shell.execute_reply":"2025-06-27T14:48:45.853297Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Mount Google Drive\n# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T14:48:45.854980Z","iopub.execute_input":"2025-06-27T14:48:45.855384Z","iopub.status.idle":"2025-06-27T14:48:45.858305Z","shell.execute_reply.started":"2025-06-27T14:48:45.855365Z","shell.execute_reply":"2025-06-27T14:48:45.857802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install pillow_heif","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T15:10:48.762502Z","iopub.execute_input":"2025-06-27T15:10:48.763084Z","iopub.status.idle":"2025-06-27T15:10:53.886583Z","shell.execute_reply.started":"2025-06-27T15:10:48.763061Z","shell.execute_reply":"2025-06-27T15:10:53.885656Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport glob\nfrom PIL import Image\nimport pillow_heif\npillow_heif.register_heif_opener()\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models\nimport torchvision.transforms.v2 as T\nfrom torchvision.transforms.v2.functional import to_image\nimport pandas as pd\nfrom tqdm import tqdm\nimport time\nimport copy\nimport matplotlib.pyplot as plt\nimport random\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T15:10:53.888308Z","iopub.execute_input":"2025-06-27T15:10:53.888597Z","iopub.status.idle":"2025-06-27T15:11:02.624042Z","shell.execute_reply.started":"2025-06-27T15:10:53.888571Z","shell.execute_reply":"2025-06-27T15:11:02.623228Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Đường dẫn dữ liệu\nsource_path = r'/kaggle/input/do-an-ml-an/ML-Do-An'\nimage_paths = []\n\nfor category_dir in glob.glob(os.path.join(source_path, '*', 'hand_written_digit', '??52????')):\n    for digit in range(10):\n        search_pattern = os.path.join(category_dir, f'{digit}_*.*')\n        found_images = glob.glob(search_pattern)\n        image_paths.extend(found_images)\n\nprint(f\"Total images collected: {len(image_paths)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T15:11:02.624961Z","iopub.execute_input":"2025-06-27T15:11:02.625430Z","iopub.status.idle":"2025-06-27T15:11:03.626875Z","shell.execute_reply.started":"2025-06-27T15:11:02.625403Z","shell.execute_reply":"2025-06-27T15:11:03.626082Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dataset cho ảnh gán nhãn\nclass DigitDataset(Dataset):\n    def __init__(self, paths, aug=None):\n        self.paths = paths\n        self.aug = aug\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __load_image(self, file_path):\n        try:\n            img = Image.open(file_path).convert(\"RGB\")\n            label = int(os.path.basename(file_path)[0])\n            if self.aug:\n                img = self.aug(img)\n            return img, label\n        except Exception as ex:\n            print(f\"Cannot read {file_path}: {ex}\")\n            return None # torch.zeros(3, 288, 288), 0\n\n    def __getitem__(self, index):\n        return self.__load_image(self.paths[index])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T15:11:03.628580Z","iopub.execute_input":"2025-06-27T15:11:03.628806Z","iopub.status.idle":"2025-06-27T15:11:03.635008Z","shell.execute_reply.started":"2025-06-27T15:11:03.628788Z","shell.execute_reply":"2025-06-27T15:11:03.634199Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Augmentation cho ảnh chữ số 0-9\n\n#Chỉ resize ảnh \ntrain_no_aug = T.Compose([\n    T.Resize((288, 288)),                            \n    T.ToImage(),                                     \n    T.ToDtype(torch.float32, scale=True),\n    # T.Normalize([0.485, 0.456, 0.406],                \n    #             [0.229, 0.224, 0.225])\n])\n\n#Tăng cường cơ bản\ntrain_aug_basic = T.Compose([\n    T.Resize((288, 288)),                            # Resize ảnh về kích thước cố định\n    T.RandomRotation(degrees=15),                    # Xoay ảnh ngẫu nhiên ±15 độ\n    T.ToImage(),                                     \n    T.ToDtype(torch.float32, scale=True),            \n    T.Normalize([0.485, 0.456, 0.406],                \n                [0.229, 0.224, 0.225])\n])\n\n#Tăng cường nâng cao\ntrain_aug_advanced = T.Compose([\n    T.Resize((288, 288)),                            # Resize ảnh về kích thước cố định\n    T.RandomRotation(degrees=15),                    # Xoay ảnh ngẫu nhiên ±15 độ\n    T.RandomHorizontalFlip(p=0.3),                   # Lật ngang ảnh với xác suất 30%\n    T.RandomAffine(degrees=0, translate=(0.1, 0.1)), # Dịch ảnh theo trục x, y (tối đa 10%)\n    T.ColorJitter(brightness=0.2, contrast=0.2),     # Thay đổi độ sáng & tương phản\n    T.RandomPerspective(distortion_scale=0.2, p=0.3),# Biến dạng phối cảnh nhẹ\n    T.ToImage(),                                     \n    T.ToDtype(torch.float32, scale=True),            \n    T.Normalize([0.485, 0.456, 0.406],                \n                [0.229, 0.224, 0.225])\n])\n\ntest_aug = T.Compose([\n    T.Resize((288, 288)),\n    T.ToImage(),\n    T.ToDtype(torch.float32, scale=True),\n    T.Normalize([0.485, 0.456, 0.406],\n                [0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T15:11:03.635791Z","iopub.execute_input":"2025-06-27T15:11:03.636052Z","iopub.status.idle":"2025-06-27T15:11:03.654829Z","shell.execute_reply.started":"2025-06-27T15:11:03.636035Z","shell.execute_reply":"2025-06-27T15:11:03.654017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Split dữ liệu không augment\n# train_size = int(0.9 * len(image_paths))\n# train_set = DigitDataset(image_paths[:train_size], aug= train_no_aug)\n# val_set = DigitDataset(image_paths[train_size:], aug= test_aug)\n\n# Split dữ liệu có augment\ntrain_size = int(0.9 * len(image_paths))\ntrain_set = DigitDataset(image_paths[:train_size], aug= train_no_aug)\nval_set = DigitDataset(image_paths[train_size:], aug= test_aug)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T15:11:03.655670Z","iopub.execute_input":"2025-06-27T15:11:03.655923Z","iopub.status.idle":"2025-06-27T15:11:03.676043Z","shell.execute_reply.started":"2025-06-27T15:11:03.655902Z","shell.execute_reply":"2025-06-27T15:11:03.675264Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\n\n# Đảo normalize nếu ảnh RGB\nmean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\nstd = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n\nplt.figure(figsize=(20, 4))\n\nstart_idx = 1000\nend_idx = 1010\n\nfor i, idx in enumerate(range(start_idx, end_idx + 1)):\n    img, label = train_set[idx]\n\n    img_denorm = img * std + mean\n    img_np = img_denorm.permute(1, 2, 0).numpy()\n\n    plt.subplot(1, end_idx - start_idx + 1, i + 1)\n    plt.imshow(img_np)\n    plt.title(f\"Label: {label}\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T15:11:03.676907Z","iopub.execute_input":"2025-06-27T15:11:03.677171Z","iopub.status.idle":"2025-06-27T15:11:06.759565Z","shell.execute_reply.started":"2025-06-27T15:11:03.677146Z","shell.execute_reply":"2025-06-27T15:11:06.758877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(train_set))\nprint(len(val_set))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T15:11:06.760488Z","iopub.execute_input":"2025-06-27T15:11:06.760773Z","iopub.status.idle":"2025-06-27T15:11:06.765385Z","shell.execute_reply.started":"2025-06-27T15:11:06.760746Z","shell.execute_reply":"2025-06-27T15:11:06.764459Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def remove_none_samples(batch):\n    return torch.utils.data.dataloader.default_collate([item for item in batch if item is not None])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T15:11:06.766242Z","iopub.execute_input":"2025-06-27T15:11:06.766499Z","iopub.status.idle":"2025-06-27T15:11:06.784661Z","shell.execute_reply.started":"2025-06-27T15:11:06.766481Z","shell.execute_reply":"2025-06-27T15:11:06.784007Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dataloader\ntrain_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=2, collate_fn=remove_none_samples)\nval_loader = DataLoader(val_set, batch_size=64, shuffle=True, num_workers=2, collate_fn=remove_none_samples)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T15:11:06.786474Z","iopub.execute_input":"2025-06-27T15:11:06.786740Z","iopub.status.idle":"2025-06-27T15:11:06.801141Z","shell.execute_reply.started":"2025-06-27T15:11:06.786725Z","shell.execute_reply":"2025-06-27T15:11:06.800415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Model setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Computation will run on: {device}\")\n\n# #model = models.efficientnet_b1(weights=models.EfficientNet_B1_Weights.IMAGENET1K_V2)\n# model = models.efficientnet_b2(weights=models.EfficientNet_B2_Weights.IMAGENET1K_V1)\n# in_features = model.classifier[1].in_features\n# model.classifier = nn.Sequential(\n#     nn.Dropout(p=0.3, inplace=True),\n#     nn.Linear(in_features, 10)\n# )\n# model = model.to(device)\n\nmodel = models.regnet_y_1_6gf(weights=models.RegNet_Y_1_6GF_Weights.IMAGENET1K_V1)\nin_features = model.fc.in_features\nmodel.fc = nn.Sequential(\n    nn.Dropout(p=0.3, inplace=True),\n    nn.Linear(in_features, 10)\n)\n\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T15:11:07.543426Z","iopub.execute_input":"2025-06-27T15:11:07.543971Z","iopub.status.idle":"2025-06-27T15:11:08.400976Z","shell.execute_reply.started":"2025-06-27T15:11:07.543948Z","shell.execute_reply":"2025-06-27T15:11:08.400171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Optimizer, Loss\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T15:11:14.774676Z","iopub.execute_input":"2025-06-27T15:11:14.774975Z","iopub.status.idle":"2025-06-27T15:11:14.780458Z","shell.execute_reply.started":"2025-06-27T15:11:14.774951Z","shell.execute_reply":"2025-06-27T15:11:14.779655Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def training(model, loss_fn, optimizer,\n             train_loader, val_loader,\n             num_epochs=15, patience=2, model_path='best_model.pth'):\n    \n    best_score = 0.0\n    best_weights = copy.deepcopy(model.state_dict())\n    no_gain = 0\n    start_time = time.time()\n\n    for ep in range(num_epochs):\n        print(f\"\\nEpoch {ep}/{num_epochs-1}\")\n        print('-'*30)\n\n        for phase in ['train', 'val']:\n            model.train() if phase == 'train' else model.eval()\n            loader = train_loader if phase == 'train' else val_loader\n\n            epoch_loss = 0.0\n            correct = 0\n\n            for imgs, lbls in tqdm(loader):\n                imgs, lbls = imgs.to(device), lbls.to(device)\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    preds = model(imgs)\n                    loss = loss_fn(preds, lbls)\n                    _, predicted = torch.max(preds, 1)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                epoch_loss += loss.item() * imgs.size(0)\n                correct += torch.sum(predicted == lbls.data)\n\n            acc = correct.double() / len(loader.dataset)\n            avg_loss = epoch_loss / len(loader.dataset)\n            print(f\"{phase.capitalize()} Loss: {avg_loss:.4f}, Acc: {acc:.4f}\")\n\n            if phase == 'val':\n                if acc > best_score:\n                    best_score = acc\n                    best_weights = copy.deepcopy(model.state_dict())\n                    no_gain = 0\n                    torch.save(model.state_dict(), model_path)\n                    print(f\"Saved best model at acc: {best_score:.4f}\")\n                else:\n                    no_gain += 1\n                    print(f\"No improvement after {no_gain} epoch(s)\")\n\n        if no_gain >= patience:\n            print(\"Early stopping.\")\n            break\n\n    duration = time.time() - start_time\n    print(f\"\\nTraining completed in {duration//60:.0f}m {duration%60:.0f}s\")\n    print(f\"Best validation accuracy: {best_score:.4f}\")\n\n    model.load_state_dict(best_weights)\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T15:11:15.998520Z","iopub.execute_input":"2025-06-27T15:11:15.999233Z","iopub.status.idle":"2025-06-27T15:11:16.007776Z","shell.execute_reply.started":"2025-06-27T15:11:15.999207Z","shell.execute_reply":"2025-06-27T15:11:16.006948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Huấn luyện\nmodel_save_path = '/kaggle/working/best_model.pth'\nmodel = training(model, loss_fn, optimizer,train_loader, val_loader,\n                 num_epochs=15, patience=2,model_path=model_save_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T14:50:36.808444Z","iopub.execute_input":"2025-06-27T14:50:36.808708Z","iopub.status.idle":"2025-06-27T14:53:47.562934Z","shell.execute_reply.started":"2025-06-27T14:50:36.808690Z","shell.execute_reply":"2025-06-27T14:53:47.561670Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dataset ảnh không nhãn\neval_dir = r'/kaggle/input/data-2025'\neval_paths = []\n\nfor dirpath, _, files in os.walk(eval_dir):\n    for fname in files:\n        if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.heic', '.jfif')):\n            eval_paths.append(os.path.join(dirpath, fname))\n        else:\n            print(f\"Skipping: {fname}\")\n\nprint(f\"Total validate images: {len(eval_paths)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T15:11:45.978707Z","iopub.execute_input":"2025-06-27T15:11:45.979443Z","iopub.status.idle":"2025-06-27T15:11:49.047586Z","shell.execute_reply.started":"2025-06-27T15:11:45.979419Z","shell.execute_reply":"2025-06-27T15:11:49.046936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EvalDataset(Dataset):\n    def __init__(self, img_list, transform=None):\n        self.img_list = img_list\n        self.transform = transform\n\n    def __getitem__(self, idx):\n        path = self.img_list[idx]\n        try: \n            # Bỏ qua những file quá bé\n            if os.path.getsize(path) < 10:\n                return torch.zeros((3, 288, 288), dtype=torch.float32), os.path.basename(path)\n\n            img = Image.open(path).convert(\"RGB\")\n            img = to_image(img)\n            if self.transform:\n                img = self.transform(img)\n            return img, os.path.basename(path)\n        except Exception as err:\n            print(f\"Failed: {path} - {err}\")\n            return torch.zeros((3, 288, 288), dtype=torch.float32), os.path.basename(path)\n\n    def __len__(self):\n        return len(self.img_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T15:16:20.696213Z","iopub.execute_input":"2025-06-27T15:16:20.696585Z","iopub.status.idle":"2025-06-27T15:16:20.703771Z","shell.execute_reply.started":"2025-06-27T15:16:20.696555Z","shell.execute_reply":"2025-06-27T15:16:20.703058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# DataLoader\neval_dataset = EvalDataset(eval_paths, transform=test_aug)\neval_loader = DataLoader(eval_dataset, batch_size=64, shuffle=True, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T14:49:06.371901Z","iopub.status.idle":"2025-06-27T14:49:06.372147Z","shell.execute_reply.started":"2025-06-27T14:49:06.372000Z","shell.execute_reply":"2025-06-27T14:49:06.372008Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load model để dự đoán\nmodel.load_state_dict(torch.load(model_save_path, map_location=device))\nmodel = model.to(device)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T14:49:06.373001Z","iopub.status.idle":"2025-06-27T14:49:06.373264Z","shell.execute_reply.started":"2025-06-27T14:49:06.373119Z","shell.execute_reply":"2025-06-27T14:49:06.373128Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dự đoán\nall_preds, all_names = [], []\nwith torch.no_grad():\n    for imgs, names in tqdm(eval_loader):\n        imgs = imgs.to(device)\n        outputs = model(imgs)\n        _, preds = torch.max(outputs, 1)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_names.extend(names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T14:49:06.374137Z","iopub.status.idle":"2025-06-27T14:49:06.374416Z","shell.execute_reply.started":"2025-06-27T14:49:06.374254Z","shell.execute_reply":"2025-06-27T14:49:06.374268Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Xuất kết quả\nresults_df = pd.DataFrame({'Filename': all_names, 'Prediction': all_preds})\nresults_df.to_csv('/kaggle/working/predictions.csv', header=False, index=False)\nprint(\"Done writing predictions.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T14:49:06.375115Z","iopub.status.idle":"2025-06-27T14:49:06.375411Z","shell.execute_reply.started":"2025-06-27T14:49:06.375238Z","shell.execute_reply":"2025-06-27T14:49:06.375253Z"}},"outputs":[],"execution_count":null}]}